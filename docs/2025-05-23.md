# 2025-04-27 - first entry!

## background
language model project:
* 500 - 700 m params
* muon, softpick, value residual connections, multi head latent attn, min-p sampling
* want to maximize conversational coherence 
* will be trained on 1 nvidia rtx 4080 gpu


progress:
* forked the modded gpt speedrun code and made it compatible for 1 gpu (removed distributed logic)
* still have to add multi-head latent attention and some other novel stuff

## today
one of the biggest problems I had was getting the flex attention to work on a single GPU, since a lot of the GEMM max autotune kernels only load if the stream multiprocessor count is over 70 but mine is 58 so i couldn't compile the entire model, but the flex attention works. 

i then had exploding loss where my loss went from like 0 -> 100000 after a single step. realized it was because the loss was summing instead of averaging which caused it to explode. changing that made the initial loss 10, which seems correct.

## tomorrow
* finish setting up wandb
* finish model code

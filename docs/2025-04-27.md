# 2025-04-27 - first entry!

## background
language model project:
* 500 - 700 m params
* muon, scalable softmax, value residual connections, multi head latent attn, min-p sampling
* want to maximize conversational coherence 
* will be trained on 1 nvidia rtx 4080 gpu

gonna have 1 'toy' model (90m params for ablation testing) and a main one


progress:
* still writing model code (mla)

## today
gonna try to finish as much of the model code as possible

7:20pm
* finished all of the mla code. The one on the deepseek repo only works for inference since the masking assumes seq_len = 1.
* nvim config getting soooo much better. total game changer. like the harpoon thing, ctrl-i/o, oil.nvim... amazing... :D


notes:
* during training, seq_len = total_len and start_pos = 0. during inference, seq_len = 1.

## tomorrow
have 2 config.yamls locking in the hyperparams?
